{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "mean = torch.tensor([0.485, 0.456, 0.406]).reshape((3, 1, 1))\n",
    "std = torch.tensor([0.229, 0.224, 0.225]).reshape((3, 1, 1))\n",
    "\n",
    "class TransformerNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransformerNet, self).__init__()\n",
    "        self.pool = nn.AvgPool2d(2)\n",
    "        self.model = nn.Sequential(\n",
    "            ConvBlock(3, 32, kernel_size=9, stride=1),\n",
    "            ConvBlock(32, 64, kernel_size=3, stride=2),\n",
    "            ConvBlock(64, 128, kernel_size=3, stride=2),\n",
    "            ResidualBlock(128),\n",
    "            ResidualBlock(128),\n",
    "            ResidualBlock(128),\n",
    "            ResidualBlock(128),\n",
    "            ResidualBlock(128),\n",
    "            ConvBlock(128, 64, kernel_size=3, upsample=True),\n",
    "            ConvBlock(64, 32, kernel_size=3, upsample=True),\n",
    "            ConvBlock(32, 3, kernel_size=9, stride=1, normalize=False, relu=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(x)\n",
    "        x = x.transpose(2, 3)\n",
    "        x = x.flip(3)\n",
    "        # x = (x - mean) / std\n",
    "        # y = self.model(x)\n",
    "        # y = y * std + mean\n",
    "        # y = torch.clamp(y * 255, 0, 255)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResidualBlock(torch.nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            ConvBlock(channels, channels, kernel_size=3, stride=1, normalize=True, relu=True),\n",
    "            ConvBlock(channels, channels, kernel_size=3, stride=1, normalize=True, relu=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x) + x\n",
    "\n",
    "\n",
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, upsample=False, normalize=True, relu=True):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.upsample = upsample\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(kernel_size // 2), nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "        )\n",
    "        self.norm = nn.InstanceNorm2d(out_channels, affine=True) if normalize else None\n",
    "        self.relu = relu\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.upsample:\n",
    "            x = F.interpolate(x, scale_factor=2)\n",
    "        x = self.block(x)\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "        if self.relu:\n",
    "            x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting PyTorch Frontend ==> MIL Ops:  93%|█████████▎| 14/15 [00:00<00:00, 7905.26 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|██████████| 5/5 [00:00<00:00, 9438.13 passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 88/88 [00:00<00:00, 5344.69 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 7518.92 passes/s]\n"
     ]
    }
   ],
   "source": [
    "import coremltools as ct\n",
    "\n",
    "def load_model(checkpoint = None):\n",
    "    model = TransformerNet()\n",
    "    if checkpoint is not None:\n",
    "        model.load_state_dict(torch.load(checkpoint, map_location=torch.device('cpu')))\n",
    "    return model\n",
    "\n",
    "def trace(model):\n",
    "    with torch.no_grad(), torch.inference_mode(), torch.jit.optimized_execution(True):\n",
    "        model.eval()\n",
    "        return torch.jit.trace_module(\n",
    "            model,\n",
    "            { 'forward': (\n",
    "                torch.ones((1, 3, 720, 1280), dtype=torch.float32),\n",
    "            ) },\n",
    "            strict=True,\n",
    "            check_trace=True,\n",
    "            check_tolerance=1e-9,\n",
    "        )\n",
    "    \n",
    "def convert(model):\n",
    "    return ct.convert(\n",
    "        model,\n",
    "        inputs=[\n",
    "            ct.ImageType(name=\"source\", shape=(1, 3, 720, 1280)),\n",
    "        ],\n",
    "        outputs=[\n",
    "            ct.ImageType(name=\"styled\")\n",
    "        ],\n",
    "        compute_units=ct.ComputeUnit.CPU_AND_NE,\n",
    "        compute_precision=ct.precision.FLOAT16,\n",
    "        minimum_deployment_target=ct.target.iOS17,\n",
    "    )\n",
    "\n",
    "def convert_pipeline(checkpoint, name):\n",
    "    model = load_model(checkpoint)\n",
    "    traced = trace(model)\n",
    "    converted = convert(traced)\n",
    "    converted.save(f\"{name}.mlpackage\")\n",
    "    return converted\n",
    "\n",
    "# cuphead = convert_pipeline(\"/Users/zeruichen/Downloads/cuphead_10000.pth\", \"CupheadStylizer.mlpackage\")\n",
    "# starry_night = convert_pipeline(\"/Users/zeruichen/Downloads/starry_night_10000.pth\", \"StarryNightStylizer.mlpackage\")\n",
    "# mosaic = convert_pipeline(\"/Users/zeruichen/Downloads/mosaic_10000.pth\", \"MosaicStylizer.mlpackage\")\n",
    "identity = convert_pipeline(None, \"IdentityStylizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in [\n",
    "    (\"CupheadStylizer\", cuphead),\n",
    "    (\"StarryNightStylizer\", starry_night),\n",
    "    (\"MosaicStylizer\", mosaic),\n",
    "]:\n",
    "    img = Image.open(\"/Users/zeruichen/Downloads/mountain.png\")\n",
    "    styled = model.predict({\"source\": img})[\"styled\"]\n",
    "    styled.save(f\"{name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running activation compression pass insert_prefix_quantize_dequantize_pair: 100%|██████████| 281/281 [00:00<00:00, 15706.07 ops/s]\n",
      "Running compression pass linear_quantize_activations: start calibrating 10 samples\n",
      "Running compression pass linear_quantize_activations: calibration may take a while ...\n",
      "Running compression pass linear_quantize_activations: calibrating sample 1/10 succeeds.\n",
      "Running compression pass linear_quantize_activations: calibrating sample 2/10 succeeds.\n",
      "Running compression pass linear_quantize_activations: calibrating sample 3/10 succeeds.\n",
      "Running compression pass linear_quantize_activations: calibrating sample 4/10 succeeds.\n",
      "Running compression pass linear_quantize_activations: calibrating sample 5/10 succeeds.\n",
      "Running compression pass linear_quantize_activations: calibrating sample 6/10 succeeds.\n",
      "Running compression pass linear_quantize_activations: calibrating sample 7/10 succeeds.\n",
      "Running compression pass linear_quantize_activations: calibrating sample 8/10 succeeds.\n",
      "Running compression pass linear_quantize_activations: calibrating sample 9/10 succeeds.\n",
      "Running compression pass linear_quantize_activations: calibrating sample 10/10 succeeds.\n",
      "Running MIL frontend_milinternal pipeline: 0 passes [00:00, ? passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 86/86 [00:00<00:00, 181.51 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 274.35 passes/s]\n"
     ]
    }
   ],
   "source": [
    "import coremltools.optimize as cto\n",
    "\n",
    "activation_config = cto.coreml.OptimizationConfig(\n",
    "    global_config = cto.coreml.experimental.OpActivationLinearQuantizerConfig(\n",
    "        mode=\"linear_symmetric\"\n",
    "    )\n",
    ")\n",
    "compressed_model_a8 = cto.coreml.experimental.linear_quantize_activations(\n",
    "    ct_model, activation_config, sample_images[:10]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running compression pass linear_quantize_weights: 100%|██████████| 61/61 [00:00<00:00, 1509.27 ops/s]\n",
      "Running MIL frontend_milinternal pipeline: 0 passes [00:00, ? passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 86/86 [00:00<00:00, 200.89 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 245.36 passes/s]\n"
     ]
    }
   ],
   "source": [
    "config = ct.optimize.coreml.OptimizationConfig(\n",
    "    global_config=ct.optimize.coreml.OpLinearQuantizerConfig(mode=\"linear\", weight_threshold=2048)\n",
    ")\n",
    "compressed_model_a8w8 = ct.optimize.coreml.linear_quantize_weights(compressed_model_a8, config=config)\n",
    "\n",
    "compressed_model_a8w8.save('../chao24/MosaicStylizerQ.mlpackage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running compression pass palettize_weights: 100%|██████████| 61/61 [00:01<00:00, 57.89 ops/s]\n",
      "Running MIL frontend_milinternal pipeline: 0 passes [00:00, ? passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 86/86 [00:00<00:00, 341.13 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 404.49 passes/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Joint compression is only supported since iOS18. Please set the minimum deployment target to iOS18 if you want to use it.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m op_config \u001b[38;5;241m=\u001b[39m OpLinearQuantizerConfig(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear_symmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \n\u001b[1;32m     22\u001b[0m                                     granularity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mper_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m linear_weight_quantize_config \u001b[38;5;241m=\u001b[39m OptimizationConfig(global_config\u001b[38;5;241m=\u001b[39mop_config)\n\u001b[0;32m---> 25\u001b[0m mlmodel_palettized_with_8bit_lut \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_quantize_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlmodel_palettized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mlinear_weight_quantize_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mjoint_compression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/coremltools/optimize/coreml/_post_training_quantization.py:48\u001b[0m, in \u001b[0;36m_multifunction_unsupported.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39m_is_multifunction():\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not supported for a multifunction model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/coremltools/optimize/coreml/_post_training_quantization.py:183\u001b[0m, in \u001b[0;36mlinear_quantize_weights\u001b[0;34m(mlmodel, config, joint_compression)\u001b[0m\n\u001b[1;32m    179\u001b[0m blockwise_weight_quantizer \u001b[38;5;241m=\u001b[39m PASS_REGISTRY[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression::linear_quantize_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    180\u001b[0m blockwise_weight_quantizer\u001b[38;5;241m.\u001b[39mset_options(\n\u001b[1;32m    181\u001b[0m     [PassOption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m, config), PassOption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoint_compression\u001b[39m\u001b[38;5;124m\"\u001b[39m, joint_compression)]\n\u001b[1;32m    182\u001b[0m )\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_model_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_graph_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblockwise_weight_quantizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/coremltools/models/utils.py:1336\u001b[0m, in \u001b[0;36m_apply_graph_pass\u001b[0;34m(mlmodel, graph_pass, spec_version, skip_model_load, pymil_load_func, return_pymil_prog)\u001b[0m\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;66;03m# Apply graph pass.\u001b[39;00m\n\u001b[1;32m   1333\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1334\u001b[0m     graph_pass, _AbstractGraphPass\n\u001b[1;32m   1335\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph pass must be an AbstractGraphPass instance, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(graph_pass)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1336\u001b[0m \u001b[43mgraph_pass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1338\u001b[0m \u001b[38;5;66;03m# An early return can prevent running all other optimization paths triggered by _mil_convert.\u001b[39;00m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_pymil_prog:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/coremltools/optimize/coreml/_quantization_passes.py:138\u001b[0m, in \u001b[0;36mAbstractCompressionPass.apply\u001b[0;34m(self, prog)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_op(op)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m prog\u001b[38;5;241m.\u001b[39mfunctions\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m--> 138\u001b[0m     \u001b[43mapply_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/helper.py:64\u001b[0m, in \u001b[0;36mblock_context_manager.<locals>.wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe function decorated with block_context_manager must have a Block \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype argument as the first input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m     )\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m block:\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/coremltools/optimize/coreml/_quantization_passes.py:112\u001b[0m, in \u001b[0;36mAbstractCompressionPass.apply.<locals>.apply_block\u001b[0;34m(block)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_joint_compression \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_current_opset_version_compatible_with(\n\u001b[1;32m    110\u001b[0m     AvailableTarget\u001b[38;5;241m.\u001b[39miOS18\n\u001b[1;32m    111\u001b[0m ):\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJoint compression is only supported since iOS18. Please set the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimum deployment target to iOS18 if you want to use it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m     )\n\u001b[1;32m    117\u001b[0m valid_consts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(block\u001b[38;5;241m.\u001b[39moperations):\n",
      "\u001b[0;31mValueError\u001b[0m: Joint compression is only supported since iOS18. Please set the minimum deployment target to iOS18 if you want to use it."
     ]
    }
   ],
   "source": [
    "from coremltools.optimize.coreml import (\n",
    "   OptimizationConfig,\n",
    "   OpPalettizerConfig,\n",
    "   OpLinearQuantizerConfig,\n",
    "   palettize_weights,\n",
    "   linear_quantize_weights,\n",
    " ) \n",
    "     \n",
    "# mlmodel: an uncompressed mlpackage, loaded into memory \n",
    "                                                                          \n",
    "# first palettize the model\n",
    "# this will produce an LUT with Float values\n",
    "op_config = OpPalettizerConfig(nbits=4)\n",
    "config = OptimizationConfig(global_config=op_config)\n",
    "mlmodel_palettized = palettize_weights(ct_model, config)\n",
    "\n",
    "# now apply weight quantization on the model, \n",
    "# with \"joint_compression\" set to True. \n",
    "# this will result in quantizing the LUT to 8 bits. \n",
    "# (granularity must be set to \"per-tensor\" for this scenario) \n",
    "op_config = OpLinearQuantizerConfig(mode=\"linear_symmetric\",  \n",
    "                                    granularity=\"per_tensor\")\n",
    "linear_weight_quantize_config = OptimizationConfig(global_config=op_config)\n",
    "\n",
    "mlmodel_palettized_with_8bit_lut = linear_quantize_weights(mlmodel_palettized, \n",
    "                                                           linear_weight_quantize_config, \n",
    "                                                           joint_compression=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlmodel_palettized_with_8bit_lut.save('../chao24/MosaicStylizer.mlpackage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coremltools.optimize.torch.palettization import PostTrainingPalettizer, PostTrainingPalettizerConfig\n",
    "\n",
    "# load model\n",
    "palettization_config_dict = {\n",
    "  \"global_config\": {\"n_bits\": 4, \"granularity\": \"per_grouped_channel\", \"group_size\": 4},\n",
    "}\n",
    "palettization_config = PostTrainingPalettizerConfig.from_dict(palettization_config_dict)\n",
    "palettizer = PostTrainingPalettizer(model, palettization_config)\n",
    "\n",
    "palettized_torch_model = palettizer.compress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(), torch.inference_mode(), torch.jit.optimized_execution(True):\n",
    "    palettized_torch_model.eval()\n",
    "    palettized_model_traced = torch.jit.trace_module(\n",
    "        palettized_torch_model,\n",
    "        { 'forward': (\n",
    "            torch.ones((1, 3, 720, 1280), dtype=torch.float32),\n",
    "        ) },\n",
    "        strict=True,\n",
    "        check_trace=True,\n",
    "        check_tolerance=1e-9,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_palettized_model = ct.convert(\n",
    "    palettized_model_traced,\n",
    "    inputs=[\n",
    "        ct.ImageType(name=\"source\", shape=(1, 3, 720, 1280), scale=1/255.0),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ct.ImageType(name=\"styled\"),\n",
    "    ],\n",
    "    compute_units=ct.ComputeUnit.CPU_ONLY,\n",
    "    compute_precision=ct.precision.FLOAT16,\n",
    "    minimum_deployment_target=ct.target.iOS18,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_palettized_model.save('../chao24/MosaicStylizer.mlpackage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools as ct\n",
    "mm = ct.models.MLModel('/Users/zeruichen/Downloads/MobileNetV2Alpha1SymmetricPerChannel.mlpackage')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
